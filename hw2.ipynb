{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd76392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da5033",
   "metadata": {},
   "source": [
    "# Qustion 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58ae07ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_6856/1593771623.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\23231\\AppData\\Local\\Temp/ipykernel_6856/1593771623.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    for n in range(len(sample_list)):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "op = []\n",
    "for m in range(len(sample_list)):\n",
    "    li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][0] == sample_list[n][0] and\n",
    "                    sample_list[m][3] != sample_list[n][3]):\n",
    "                li.append(sample_list[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[3], reverse=True)[0])\n",
    "res = list(set(op))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8391c4f7",
   "metadata": {},
   "source": [
    "- (a) What does the code do?\n",
    "\n",
    "It first classifies tuples in the list according to the value of the first item, then select the tuple with the largest last item in each category, and returns all these tuples without repitition.\n",
    "- (b) Code review\n",
    "   - Working part\n",
    "   \n",
    "     The code can express the writer's thoughts, but unfortunately, it doesn't work. There are several syntax errors in this code. The second \"for\" loop is supposed to be aligned with the assignment line, and the list range is zero to length-1, not 0 to length.\n",
    "   - Style\n",
    "     \n",
    "     It doesn't follow the style guidelines.\n",
    "   - Structure\n",
    "     \n",
    "     It is clearly structured. The writer used two loops and it's easy to see his idea.\n",
    "   - Efficiency\n",
    "   \n",
    "     The efficiency can be improved. For example, this code uses `sample_list[m]` several times. for the \"if\" statement in the second loop, it can be replaced by `li[0]`.And there's no need to judge whether `sample_list[m][3]` is equal to `sample_list[n][3]`, because the `set` part will remove duplicate values.\n",
    "     \n",
    "   - Suggestion\n",
    "     First, maybe the code writer should focus more on the use of \"tab\", and check the alignment and foot numbers in the code more carefully. Second, when a variable is used many times, maybe the writer can notice it and temporarily store it in a parameter. Third, focus more on the details of the code. Moreover, the writer may use a function and do your work in a more general way.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0235d26b",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad593a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 5, 0, 0), (8, 6, 3, 4), (5, 9, 0, 5), (2, 9, 6, 4), (5, 5, 5, 7)]\n"
     ]
    }
   ],
   "source": [
    "def f(n, k = 4, low = 0, high = 10):\n",
    "    '''\n",
    "    return a list of n-tuples with k random integers between low and high.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int TYPE\n",
    "        The number of tuples.\n",
    "    k : int TYPE, optional\n",
    "        The number of random integers. The default is 4.\n",
    "    low :int TYPE, optional\n",
    "        The lower bound. The default is 0.\n",
    "    high :int TYPE, optional\n",
    "        The upper bound. The default is 10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list0 :list TYPE\n",
    "        A list of n-tuples with k random integers between low and high.\n",
    "\n",
    "    '''\n",
    "    list0 = []\n",
    "    for i in range(n):\n",
    "        list0.append(tuple(np.random.randint(low,high,size=k)))\n",
    "    #assert test\n",
    "    #list0 = \"test\"\n",
    "    #list0 = [2,3]\n",
    "    assert type(list0)==list, \"Return should be a list of tuples.\"\n",
    "    for t in list0:\n",
    "        assert type(t)== tuple,\"Return should be a list of tuples.\"\n",
    "    return list0\n",
    "print(f(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ba045",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71ee48b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 9, 8, 10), (0, 1, 2, 3), (1, 3, 5, 10)]\n"
     ]
    }
   ],
   "source": [
    "def given_max1(list1, item1 = 0, item2 = 3):\n",
    "    '''\n",
    "    Classify the tuples in list1 through item1, and choose the max of item2.\n",
    "    Parameters\n",
    "    ----------\n",
    "    list1 : list TYPE\n",
    "        The list generated by the function in a.\n",
    "    item1 : int TYPE, optional\n",
    "        The classify column number. The default is 0.\n",
    "    item2 : TYPE, optional\n",
    "        The sorted column number. The default is 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list TYPE\n",
    "        a list of these \"max\" tuples.\n",
    "\n",
    "    '''\n",
    "    sample_list = list1\n",
    "    op = []\n",
    "    for m in range(len(sample_list)):\n",
    "        li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][item1] == sample_list[n][item1] and\n",
    "                    sample_list[m][item2] != sample_list[n][item2]):\n",
    "                li.append(sample_list[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[item2], reverse=True)[0])\n",
    "    return list(set(op))\n",
    "print(given_max1([(1, 3, 5, 6), (0, 1, 2, 3), (1, 9, 8, 10),(1, 3, 5, 10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1db7a421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 9, 8, 10), (0, 1, 2, 3), (1, 3, 5, 10)]\n"
     ]
    }
   ],
   "source": [
    "def given_max2(list1, item1 = 0, item2 = 3):\n",
    "    '''\n",
    "    Classify the tuples in list1 through item1, and choose the max of item2.\n",
    "    Parameters\n",
    "    ----------\n",
    "    list1 : list TYPE\n",
    "        The list generated by the function in a.\n",
    "    item1 : int TYPE, optional\n",
    "        The classify column number. The default is 0.\n",
    "    item2 : TYPE, optional\n",
    "        The sorted column number. The default is 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list TYPE\n",
    "        a list of these \"max\" tuples.\n",
    "\n",
    "    '''\n",
    "    op, leng = [], len(list1)\n",
    "    for m in range(leng):\n",
    "        a = list1[m]\n",
    "        li = [a]\n",
    "        for n in range(leng):\n",
    "            if a[item1] == list1[n][item1]:\n",
    "                li.append(list1[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[item2], reverse=True)[0])\n",
    "    return list(set(op))\n",
    "print(given_max2([(1, 3, 5, 6), (0, 1, 2, 3), (1, 9, 8, 10),(1, 3, 5, 10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "368512cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 9, 8, 10), (0, 1, 2, 3)]\n"
     ]
    }
   ],
   "source": [
    "def given_max3(list1, item1 = 0, item2 = 3):\n",
    "    '''\n",
    "    Classify the tuples in list1 through item1, and choose the max of item2.\n",
    "    Parameters\n",
    "    ----------\n",
    "    list1 : list TYPE\n",
    "        The list generated by the function in a.\n",
    "    item1 : int TYPE, optional\n",
    "        The classify column number. The default is 0.\n",
    "    item2 : TYPE, optional\n",
    "        The sorted column number. The default is 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list TYPE\n",
    "        a list of these \"max\" tuples.\n",
    "\n",
    "    '''\n",
    "    dict1 = {}\n",
    "    for tup in list1:\n",
    "        a = tup[item1]\n",
    "        if dict1.get(a) != None:\n",
    "            if dict1[a][item2] < tup[item2]:\n",
    "                dict1[a] = tup\n",
    "        else:\n",
    "            dict1[a] = tup\n",
    "    return list(dict1.values())\n",
    "print(given_max3([(1, 3, 5, 6), (0, 1, 2, 3), (1, 9, 8, 10),(1, 3, 5, 10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30011729",
   "metadata": {},
   "source": [
    "# Question3\n",
    "\n",
    "a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc6e825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        seqn  ridageyr  ridreth3  dmdeduc2  dmdmartl  ridstatr  sdmvpsu  \\\n",
      "0      93703       2.0         6      <NA>      <NA>         2        2   \n",
      "1      93704       2.0         3      <NA>      <NA>         2        1   \n",
      "2      93705      66.0         4         2         3         2        2   \n",
      "3      93706      18.0         6      <NA>      <NA>         2        2   \n",
      "4      93707      13.0         7      <NA>      <NA>         2        1   \n",
      "...      ...       ...       ...       ...       ...       ...      ...   \n",
      "39151  71912      40.0         3         1         1         2        1   \n",
      "39152  71913      18.0         6      <NA>      <NA>         2        1   \n",
      "39153  71914      10.0         3      <NA>      <NA>         2        2   \n",
      "39154  71915      60.0         3         5         5         2        3   \n",
      "39155  71916      16.0         3      <NA>      <NA>         2        1   \n",
      "\n",
      "       sdmvstra      wtmec2yr      wtint2yr yearofdata  \n",
      "0           145   8539.731348   9246.491865      17-18  \n",
      "1           143   42566.61475  37338.768343      17-18  \n",
      "2           145   8338.419786   8614.571172      17-18  \n",
      "3           134   8723.439814   8548.632619      17-18  \n",
      "4           138    7064.60973   6769.344567      17-18  \n",
      "...         ...           ...           ...        ...  \n",
      "39151        98  20770.138122  19633.637051      11-12  \n",
      "39152        94   8028.485773   7382.152016      11-12  \n",
      "39153        94  63931.531988  60197.256541      11-12  \n",
      "39154        90  91446.591982  88961.259215      11-12  \n",
      "39155        94  24751.360191  24446.632088      11-12  \n",
      "\n",
      "[39156 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df1718 = pd.read_sas('DEMO_2017-2018.XPT', format = 'xport')\n",
    "df1516 = pd.read_sas('DEMO_2015-2016.XPT', format = 'xport')\n",
    "df1314 = pd.read_sas('DEMO_2013-2014.XPT', format = 'xport')\n",
    "df1112 = pd.read_sas('DEMO_2011-2012.XPT', format = 'xport')\n",
    "interest = [\"SEQN\", \"RIDAGEYR\", \"RIDRETH3\", \"DMDEDUC2\", \"DMDMARTL\", \"RIDSTATR\", \"SDMVPSU\", \"SDMVSTRA\", \"WTMEC2YR\", \"WTINT2YR\"]\n",
    "z = []\n",
    "y4 = df1718[interest]\n",
    "m, n = y4.shape[0],y4.shape[1]\n",
    "y4.insert(n,\"YEAROFDATA\",[\"17-18\"for i in range(m)])\n",
    "z.append(y4)\n",
    "y3 = df1516[interest]\n",
    "m, n = y3.shape[0],y3.shape[1]\n",
    "y3.insert(n,\"YEAROFDATA\",[\"15-16\"for i in range(m)])\n",
    "z.append(y3)\n",
    "y2 = df1314[interest]\n",
    "m, n = y2.shape[0],y2.shape[1]\n",
    "y2.insert(n,\"YEAROFDATA\",[\"13-14\"for i in range(m)])\n",
    "z.append(y2)\n",
    "y1 = df1112[interest]\n",
    "m, n = y1.shape[0],y1.shape[1]\n",
    "y1.insert(n,\"YEAROFDATA\",[\"11-12\"for i in range(m)])\n",
    "z.append(y1)\n",
    "res = pd.concat(z, axis = 0, ignore_index = True)\n",
    "res.columns = [x.lower() for x in interest]+[\"yearofdata\"]\n",
    "res = pd.DataFrame.convert_dtypes(res)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71a315",
   "metadata": {},
   "source": [
    "b)the round-trip part ( to make sure it doesn't miss any information.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ae67be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        seqn  ridageyr  ridreth3  dmdeduc2  dmdmartl  ridstatr  sdmvpsu  \\\n",
      "0      93703       2.0         6      <NA>      <NA>         2        2   \n",
      "1      93704       2.0         3      <NA>      <NA>         2        1   \n",
      "2      93705      66.0         4         2         3         2        2   \n",
      "3      93706      18.0         6      <NA>      <NA>         2        2   \n",
      "4      93707      13.0         7      <NA>      <NA>         2        1   \n",
      "...      ...       ...       ...       ...       ...       ...      ...   \n",
      "39151  71912      40.0         3         1         1         2        1   \n",
      "39152  71913      18.0         6      <NA>      <NA>         2        1   \n",
      "39153  71914      10.0         3      <NA>      <NA>         2        2   \n",
      "39154  71915      60.0         3         5         5         2        3   \n",
      "39155  71916      16.0         3      <NA>      <NA>         2        1   \n",
      "\n",
      "       sdmvstra      wtmec2yr      wtint2yr yearofdata  \n",
      "0           145   8539.731348   9246.491865      17-18  \n",
      "1           143   42566.61475  37338.768343      17-18  \n",
      "2           145   8338.419786   8614.571172      17-18  \n",
      "3           134   8723.439814   8548.632619      17-18  \n",
      "4           138    7064.60973   6769.344567      17-18  \n",
      "...         ...           ...           ...        ...  \n",
      "39151        98  20770.138122  19633.637051      11-12  \n",
      "39152        94   8028.485773   7382.152016      11-12  \n",
      "39153        94  63931.531988  60197.256541      11-12  \n",
      "39154        90  91446.591982  88961.259215      11-12  \n",
      "39155        94  24751.360191  24446.632088      11-12  \n",
      "\n",
      "[39156 rows x 11 columns]\n",
      "        seqn  ridageyr  ridreth3  dmdeduc2  dmdmartl  ridstatr  sdmvpsu  \\\n",
      "0      93703       2.0         6      <NA>      <NA>         2        2   \n",
      "1      93704       2.0         3      <NA>      <NA>         2        1   \n",
      "2      93705      66.0         4         2         3         2        2   \n",
      "3      93706      18.0         6      <NA>      <NA>         2        2   \n",
      "4      93707      13.0         7      <NA>      <NA>         2        1   \n",
      "...      ...       ...       ...       ...       ...       ...      ...   \n",
      "39151  71912      40.0         3         1         1         2        1   \n",
      "39152  71913      18.0         6      <NA>      <NA>         2        1   \n",
      "39153  71914      10.0         3      <NA>      <NA>         2        2   \n",
      "39154  71915      60.0         3         5         5         2        3   \n",
      "39155  71916      16.0         3      <NA>      <NA>         2        1   \n",
      "\n",
      "       sdmvstra      wtmec2yr      wtint2yr yearofdata  \n",
      "0           145   8539.731348   9246.491865      17-18  \n",
      "1           143   42566.61475  37338.768343      17-18  \n",
      "2           145   8338.419786   8614.571172      17-18  \n",
      "3           134   8723.439814   8548.632619      17-18  \n",
      "4           138    7064.60973   6769.344567      17-18  \n",
      "...         ...           ...           ...        ...  \n",
      "39151        98  20770.138122  19633.637051      11-12  \n",
      "39152        94   8028.485773   7382.152016      11-12  \n",
      "39153        94  63931.531988  60197.256541      11-12  \n",
      "39154        90  91446.591982  88961.259215      11-12  \n",
      "39155        94  24751.360191  24446.632088      11-12  \n",
      "\n",
      "[39156 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame.to_pickle(res, \"nhane.pkl\")\n",
    "pd.DataFrame.to_feather(res, \"nhane.feather\")\n",
    "res_pi = pd.read_pickle(\"nhane.pkl\")\n",
    "print(res_pi)\n",
    "res_f = pd.read_feather(\"nhane.feather\")\n",
    "print(res_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a05fca",
   "metadata": {},
   "source": [
    "We can see the data after round-trip format is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d72d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pandas\\io\\sas\\sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        seqn  ohddests  ohx01tc  ohx02tc  ohx03tc  ohx04tc  ohx05tc  ohx06tc  \\\n",
      "0      93703         1        4        4        4        1        1        1   \n",
      "1      93704         1        4        4        4        1        1        1   \n",
      "2      93705         1        4        2        4        2        2        2   \n",
      "3      93706         1        4        2        2        2        2        2   \n",
      "4      93707         1        4        4        2        1        1        1   \n",
      "...      ...       ...      ...      ...      ...      ...      ...      ...   \n",
      "35904  71912         1        4        2        2        2        2        2   \n",
      "35905  71913         1        2        2        2        2        2        2   \n",
      "35906  71914         1        4        4        2        1        1        1   \n",
      "35907  71915         1        2        2        2        2        2        2   \n",
      "35908  71916         1        4        2        2        2        2        2   \n",
      "\n",
      "       ohx07tc  ohx08tc  ...  ohx23ctc  ohx24ctc  ohx25ctc  ohx26ctc  \\\n",
      "0            1        1  ...      b'D'      b'D'      b'D'      b'D'   \n",
      "1            1        1  ...      b'D'      b'D'      b'D'      b'D'   \n",
      "2            2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "3            2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "4            2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "...        ...      ...  ...       ...       ...       ...       ...   \n",
      "35904        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "35905        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "35906        2        2  ...      b'Y'      b'S'      b'S'      b'S'   \n",
      "35907        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "35908        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "\n",
      "       ohx27ctc  ohx28ctc  ohx29ctc  ohx30ctc  ohx31ctc  yearofdata  \n",
      "0          b'D'      b'D'      b'D'      b'U'      b'U'       17-18  \n",
      "1          b'D'      b'D'      b'D'      b'U'      b'U'       17-18  \n",
      "2          b'S'      b'F'      b'F'      b'R'      b'F'       17-18  \n",
      "3          b'S'      b'S'      b'S'      b'S'      b'S'       17-18  \n",
      "4          b'S'      b'D'      b'S'      b'S'      b'S'       17-18  \n",
      "...         ...       ...       ...       ...       ...         ...  \n",
      "35904      b'S'      b'S'      b'S'      b'Z'      b'S'       11-12  \n",
      "35905      b'S'      b'S'      b'S'      b'S'      b'S'       11-12  \n",
      "35906      b'Y'      b'D'      b'D'      b'S'      b'U'       11-12  \n",
      "35907      b'S'      b'S'      b'S'      b'Z'      b'Z'       11-12  \n",
      "35908      b'S'      b'S'      b'S'      b'Z'      b'U'       11-12  \n",
      "\n",
      "[35909 rows x 63 columns]\n",
      "0        93703\n",
      "1        93704\n",
      "2        93705\n",
      "3        93706\n",
      "4        93707\n",
      "         ...  \n",
      "35904    71912\n",
      "35905    71913\n",
      "35906    71914\n",
      "35907    71915\n",
      "35908    71916\n",
      "Name: seqn, Length: 35909, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "dff1718 = pd.read_sas('OHXDEN_2017-2018.XPT', format = 'xport')\n",
    "dff1516 = pd.read_sas('OHXDEN_2015-2016.XPT', format = 'xport')\n",
    "dff1314 = pd.read_sas('OHXDEN_2013-2014.XPT', format = 'xport')\n",
    "dff1112 = pd.read_sas('OHXDEN_2011-2012.XPT', format = 'xport')\n",
    "total = dff1718.columns\n",
    "interest1 = ['SEQN', 'OHDDESTS'] + [x for x in total if (x[0:3] == \"OHX\" and (x[5:7] == \"TC\" or x[5:8] == \"CTC\")) ]\n",
    "for x in interest1:\n",
    "    if x not in dff1516.columns:\n",
    "        interest1.remove(x)\n",
    "for x in interest1:\n",
    "    if x not in dff1314.columns:\n",
    "        interest1.remove(x)\n",
    "for x in interest1:\n",
    "    if x not in dff1112.columns:\n",
    "        interest1.remove(x)\n",
    "z1 = []\n",
    "y8 = dff1718[interest1]\n",
    "m, n = y8.shape[0],y8.shape[1]\n",
    "y8.insert(n,\"YEAROFDATA\",[\"17-18\"for i in range(m)])\n",
    "z1.append(y8)\n",
    "y7 = dff1516[interest1]\n",
    "m, n = y7.shape[0],y7.shape[1]\n",
    "y7.insert(n,\"YEAROFDATA\",[\"15-16\"for i in range(m)])\n",
    "z1.append(y7)\n",
    "y6 = dff1314[interest1]\n",
    "m, n = y6.shape[0],y6.shape[1]\n",
    "y6.insert(n,\"YEAROFDATA\",[\"13-14\"for i in range(m)])\n",
    "z1.append(y6)\n",
    "y5 = dff1112[interest1]\n",
    "m, n = y5.shape[0],y5.shape[1]\n",
    "y5.insert(n,\"YEAROFDATA\",[\"11-12\"for i in range(m)])\n",
    "z1.append(y5)\n",
    "res1 = pd.concat(z1, axis = 0, ignore_index = True)\n",
    "res1.columns = [x.lower() for x in interest1]+[\"yearofdata\"]\n",
    "res1 = pd.DataFrame.convert_dtypes(res1)\n",
    "print(res1)\n",
    "print(res1['seqn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5c44bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        seqn  ohddests  ohx01tc  ohx02tc  ohx03tc  ohx04tc  ohx05tc  ohx06tc  \\\n",
      "0      93703         1        4        4        4        1        1        1   \n",
      "1      93704         1        4        4        4        1        1        1   \n",
      "2      93705         1        4        2        4        2        2        2   \n",
      "3      93706         1        4        2        2        2        2        2   \n",
      "4      93707         1        4        4        2        1        1        1   \n",
      "...      ...       ...      ...      ...      ...      ...      ...      ...   \n",
      "35904  71912         1        4        2        2        2        2        2   \n",
      "35905  71913         1        2        2        2        2        2        2   \n",
      "35906  71914         1        4        4        2        1        1        1   \n",
      "35907  71915         1        2        2        2        2        2        2   \n",
      "35908  71916         1        4        2        2        2        2        2   \n",
      "\n",
      "       ohx07tc  ohx08tc  ...  ohx23ctc  ohx24ctc  ohx25ctc  ohx26ctc  \\\n",
      "0            1        1  ...      b'D'      b'D'      b'D'      b'D'   \n",
      "1            1        1  ...      b'D'      b'D'      b'D'      b'D'   \n",
      "2            2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "3            2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "4            2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "...        ...      ...  ...       ...       ...       ...       ...   \n",
      "35904        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "35905        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "35906        2        2  ...      b'Y'      b'S'      b'S'      b'S'   \n",
      "35907        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "35908        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "\n",
      "       ohx27ctc  ohx28ctc  ohx29ctc  ohx30ctc  ohx31ctc  yearofdata  \n",
      "0          b'D'      b'D'      b'D'      b'U'      b'U'       17-18  \n",
      "1          b'D'      b'D'      b'D'      b'U'      b'U'       17-18  \n",
      "2          b'S'      b'F'      b'F'      b'R'      b'F'       17-18  \n",
      "3          b'S'      b'S'      b'S'      b'S'      b'S'       17-18  \n",
      "4          b'S'      b'D'      b'S'      b'S'      b'S'       17-18  \n",
      "...         ...       ...       ...       ...       ...         ...  \n",
      "35904      b'S'      b'S'      b'S'      b'Z'      b'S'       11-12  \n",
      "35905      b'S'      b'S'      b'S'      b'S'      b'S'       11-12  \n",
      "35906      b'Y'      b'D'      b'D'      b'S'      b'U'       11-12  \n",
      "35907      b'S'      b'S'      b'S'      b'Z'      b'Z'       11-12  \n",
      "35908      b'S'      b'S'      b'S'      b'Z'      b'U'       11-12  \n",
      "\n",
      "[35909 rows x 63 columns]\n",
      "        seqn  ohddests  ohx01tc  ohx02tc  ohx03tc  ohx04tc  ohx05tc  ohx06tc  \\\n",
      "0      93703         1        4        4        4        1        1        1   \n",
      "1      93704         1        4        4        4        1        1        1   \n",
      "2      93705         1        4        2        4        2        2        2   \n",
      "3      93706         1        4        2        2        2        2        2   \n",
      "4      93707         1        4        4        2        1        1        1   \n",
      "...      ...       ...      ...      ...      ...      ...      ...      ...   \n",
      "35904  71912         1        4        2        2        2        2        2   \n",
      "35905  71913         1        2        2        2        2        2        2   \n",
      "35906  71914         1        4        4        2        1        1        1   \n",
      "35907  71915         1        2        2        2        2        2        2   \n",
      "35908  71916         1        4        2        2        2        2        2   \n",
      "\n",
      "       ohx07tc  ohx08tc  ...  ohx23ctc  ohx24ctc  ohx25ctc  ohx26ctc  \\\n",
      "0            1        1  ...      b'D'      b'D'      b'D'      b'D'   \n",
      "1            1        1  ...      b'D'      b'D'      b'D'      b'D'   \n",
      "2            2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "3            2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "4            2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "...        ...      ...  ...       ...       ...       ...       ...   \n",
      "35904        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "35905        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "35906        2        2  ...      b'Y'      b'S'      b'S'      b'S'   \n",
      "35907        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "35908        2        2  ...      b'S'      b'S'      b'S'      b'S'   \n",
      "\n",
      "       ohx27ctc  ohx28ctc  ohx29ctc  ohx30ctc  ohx31ctc  yearofdata  \n",
      "0          b'D'      b'D'      b'D'      b'U'      b'U'       17-18  \n",
      "1          b'D'      b'D'      b'D'      b'U'      b'U'       17-18  \n",
      "2          b'S'      b'F'      b'F'      b'R'      b'F'       17-18  \n",
      "3          b'S'      b'S'      b'S'      b'S'      b'S'       17-18  \n",
      "4          b'S'      b'D'      b'S'      b'S'      b'S'       17-18  \n",
      "...         ...       ...       ...       ...       ...         ...  \n",
      "35904      b'S'      b'S'      b'S'      b'Z'      b'S'       11-12  \n",
      "35905      b'S'      b'S'      b'S'      b'S'      b'S'       11-12  \n",
      "35906      b'Y'      b'D'      b'D'      b'S'      b'U'       11-12  \n",
      "35907      b'S'      b'S'      b'S'      b'Z'      b'Z'       11-12  \n",
      "35908      b'S'      b'S'      b'S'      b'Z'      b'U'       11-12  \n",
      "\n",
      "[35909 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame.to_pickle(res1, \"OH.pkl\")\n",
    "pd.DataFrame.to_feather(res1, \"OH.feather\")\n",
    "res1_pi = pd.read_pickle(\"OH.pkl\")\n",
    "print(res1_pi)\n",
    "res1_f = pd.read_feather(\"OH.feather\")\n",
    "print(res1_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41185f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pandas\\io\\sas\\sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35909, 63)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import exists\n",
    "# file location: -------------------------------------------------------------\n",
    "path = './'\n",
    "\n",
    "\n",
    "# column maps: ---------------------------------------------------------------\n",
    "# new names for demo cols\n",
    "demo_cols = {\n",
    "    'SEQN': 'id',\n",
    "    'RIDAGEYR': 'age',\n",
    "    'RIAGENDR': 'gender',\n",
    "    'RIDRETH3': 'race',\n",
    "    'DMDEDUC2': 'education',\n",
    "    'DMDMARTL': 'marital_status',\n",
    "    'RIDSTATR': 'exam_status',\n",
    "    'SDMVPSU': 'psu',\n",
    "    'SDMVSTRA': 'strata',\n",
    "    'WTMEC2YR': 'exam_wt',\n",
    "    'WTINT2YR': 'interview_wt'\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# new names for ohx cols\n",
    "ohx_cols = {'SEQN': 'id', 'OHDDESTS': 'dentition_status'}\n",
    "tc_cols = {'OHX' + str(i).zfill(2) + 'TC':\n",
    "           'tc_' + str(i).zfill(2) for i in range(1, 33)}\n",
    "ctc_cols = {'OHX' + str(i).zfill(2) + 'CTC':\n",
    "            'ctc_' + str(i).zfill(2) for i in range(2, 32)}\n",
    "_, _ = ctc_cols.pop('OHX16CTC'), ctc_cols.pop('OHX17CTC')\n",
    "\n",
    "ohx_cols.update(tc_cols)\n",
    "ohx_cols.update(ctc_cols)\n",
    "\n",
    "# columns to convert to integer\n",
    "demo_int = ('id', 'age', 'psu', 'strata')\n",
    "ohx_int = ('id', )\n",
    "# levels for categorical variables\n",
    "demo_cat = {\n",
    "    'gender': {1: 'Male', 2: 'Female'},\n",
    "    'race': {1: 'Mexican American',\n",
    "             2: 'Other Hispanic',\n",
    "             3: 'Non-Hispanic White',\n",
    "             4: 'Non-Hispanic Black',\n",
    "             6: 'Non-Hispanic Asian',\n",
    "             7: 'Other/Multiracial'\n",
    "             },\n",
    "    'education': {1: 'Less than 9th grade',\n",
    "                  2: '9-11th grade (Includes 12th grade with no diploma)',\n",
    "                  3: 'High school graduate/GED or equivalent',\n",
    "                  4: 'Some college or AA degree',\n",
    "                  5: 'College graduate or above',\n",
    "                  7: 'Refused',\n",
    "                  9: \"Don't know\"\n",
    "                  },\n",
    "    'marital_status': {1: 'Married',\n",
    "                       2: 'Widowed',\n",
    "                       3: 'Divorced',\n",
    "                       4: 'Separated',\n",
    "                       5: 'Never married',\n",
    "                       6: 'Living with partner',\n",
    "                       77: 'Refused',\n",
    "                       99: \"Don't know\"\n",
    "                       },\n",
    "    'exam_status': {1: 'Interviewed only',\n",
    "                    2: 'Both interviewed and MEC examined'\n",
    "                    }\n",
    "    }\n",
    "\n",
    "ohx_cat = {\n",
    "    'dentition_status': {1: 'Complete', 2: 'Partial', 3: 'Not Done'}\n",
    "    }\n",
    "\n",
    "tc = {\n",
    "      1: 'Primary tooth present',\n",
    "      2: 'Permanent tooth present',\n",
    "      3: 'Dental Implant',\n",
    "      4: 'Tooth not present',\n",
    "      5: 'Permanent dental root fragment present',\n",
    "      9: 'Could not assess'\n",
    "      }\n",
    "ctc = (\n",
    " {\n",
    "  'A': 'Primary tooth with a restored surface condition',\n",
    "  'D': 'Sound primary tooth',\n",
    "  'E': 'Missing due to dental disease',\n",
    "  'F': 'Permanent tooth with a restored surface condition',\n",
    "  'J':\n",
    "    'Permanent root tip is present but no restorative replacement is present',\n",
    "  'K': 'Primary tooth with a dental carious surface condition',\n",
    "  'M': 'Missing due to other causes',\n",
    "  'P':\n",
    "    'Missing due to dental disease but replaced by a removable restoration',\n",
    "  'Q':\n",
    "    'Missing due to other causes but replaced by a removable restoration',\n",
    "  'R':\n",
    "    'Missing due to dental disease but replaced by a fixed restoration',\n",
    "  'S': 'Sound permanent tooth',\n",
    "  'T':\n",
    "    'Permanent root tip is present but a restorative replacement is present',\n",
    "  'U': 'Unerupted',\n",
    "  'X': 'Missing due to other causes but replaced by a fixed restoration',\n",
    "  'Y': 'Tooth present, condition cannot be assessed',\n",
    "  'Z': 'Permanent tooth with a dental carious surface condition'\n",
    " })\n",
    "# read data: -----------------------------------------------------------------\n",
    "base_url = 'https://wwwn.cdc.gov/Nchs/Nhanes/'\n",
    "cohorts = (\n",
    "    ('2011-2012', 'G'),\n",
    "    ('2013-2014', 'H'),\n",
    "    ('2015-2016', 'I'),\n",
    "    ('2017-2018', 'J')\n",
    "    )\n",
    "# demographic data\n",
    "demo_file = path + '/demo.feather'\n",
    "if exists(demo_file):\n",
    "    demo = pd.read_feather(demo_file)\n",
    "else:\n",
    "    demo_cohorts = {}\n",
    "    for cohort, label in cohorts:\n",
    "\n",
    "        # read data and subset columns\n",
    "        url = base_url + cohort + '/DEMO_' + label + '.XPT'\n",
    "        dat = pd.read_sas(url).copy()\n",
    "        dat = dat[list(demo_cols.keys())].rename(columns=demo_cols)\n",
    "\n",
    "        # assign cohort and collect\n",
    "        dat['cohort'] = cohort\n",
    "        demo_cohorts.update({cohort: dat})\n",
    "\n",
    "    # concatenate and save\n",
    "    demo = pd.concat(demo_cohorts, ignore_index=True)\n",
    " \n",
    "    # categorical variables\n",
    "    for col, d in demo_cat.items():\n",
    "        demo[col] = pd.Categorical(demo[col].replace(d))\n",
    "    demo['cohort'] = pd.Categorical(demo['cohort'])\n",
    "\n",
    "    # integer variables\n",
    "    for col in demo_int:\n",
    "        demo[col] = pd.to_numeric(demo[col], downcast='integer')\n",
    "\n",
    "    demo.to_feather(demo_file)\n",
    "demo.shape\n",
    "# dentition data\n",
    "ohx_file = path + '/ohx.feather'\n",
    "if exists(ohx_file):\n",
    "    ohx = pd.read_feather(ohx_file)\n",
    "else:\n",
    "    ohx_cohorts = {}\n",
    "    for cohort, label in cohorts:\n",
    "\n",
    "        # read data and subset columns\n",
    "        url = base_url + cohort + '/OHXDEN_' + label + '.XPT'\n",
    "        dat = pd.read_sas(url).copy()\n",
    "        dat = dat[list(ohx_cols.keys())].rename(columns=ohx_cols)\n",
    "\n",
    "        # assign cohort and collect\n",
    "        dat['cohort'] = cohort\n",
    "        ohx_cohorts.update({cohort: dat})\n",
    " \n",
    "    # concatenate\n",
    "    ohx = pd.concat(ohx_cohorts, ignore_index=True)\n",
    "\n",
    "    # categorical variables\n",
    "    for col, d in ohx_cat.items():\n",
    "        ohx[col] = pd.Categorical(ohx[col].replace(d))\n",
    "    \n",
    "    for col in tc_cols.values():\n",
    "        ohx[col] = pd.Categorical(ohx[col].replace(tc))\n",
    "\n",
    "    # ctc columns get read in as bytes\n",
    "    for col in ctc_cols.values():\n",
    "        ohx[col] = ohx[col].apply(lambda x: x.decode('utf-8'))\n",
    "        ohx[col] = pd.Categorical(ohx[col].replace(ctc))\n",
    "\n",
    "    ohx['cohort'] = pd.Categorical(ohx['cohort'])\n",
    "    # integer variables\n",
    "    for col in ohx_int:\n",
    "        ohx[col] = pd.to_numeric(ohx[col], downcast='integer')\n",
    "\n",
    "    # save\n",
    "    ohx.to_feather(ohx_file)\n",
    "ohx.shape\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7bea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id dentition_status                    tc_01  \\\n",
      "0       62161         Complete        Tooth not present   \n",
      "1       62162         Complete        Tooth not present   \n",
      "2       62163         Complete        Tooth not present   \n",
      "3       62164         Complete        Tooth not present   \n",
      "4       62165         Complete        Tooth not present   \n",
      "...       ...              ...                      ...   \n",
      "35904  102952         Complete  Permanent tooth present   \n",
      "35905  102953         Complete  Permanent tooth present   \n",
      "35906  102954         Complete  Permanent tooth present   \n",
      "35907  102955         Complete        Tooth not present   \n",
      "35908  102956         Complete        Tooth not present   \n",
      "\n",
      "                         tc_02                    tc_03  \\\n",
      "0      Permanent tooth present  Permanent tooth present   \n",
      "1            Tooth not present        Tooth not present   \n",
      "2      Permanent tooth present  Permanent tooth present   \n",
      "3      Permanent tooth present  Permanent tooth present   \n",
      "4      Permanent tooth present  Permanent tooth present   \n",
      "...                        ...                      ...   \n",
      "35904  Permanent tooth present  Permanent tooth present   \n",
      "35905  Permanent tooth present  Permanent tooth present   \n",
      "35906  Permanent tooth present  Permanent tooth present   \n",
      "35907  Permanent tooth present  Permanent tooth present   \n",
      "35908        Tooth not present  Permanent tooth present   \n",
      "\n",
      "                         tc_04                    tc_05  \\\n",
      "0      Permanent tooth present  Permanent tooth present   \n",
      "1        Primary tooth present    Primary tooth present   \n",
      "2      Permanent tooth present  Permanent tooth present   \n",
      "3      Permanent tooth present  Permanent tooth present   \n",
      "4      Permanent tooth present  Permanent tooth present   \n",
      "...                        ...                      ...   \n",
      "35904  Permanent tooth present  Permanent tooth present   \n",
      "35905  Permanent tooth present  Permanent tooth present   \n",
      "35906  Permanent tooth present  Permanent tooth present   \n",
      "35907  Permanent tooth present  Permanent tooth present   \n",
      "35908  Permanent tooth present  Permanent tooth present   \n",
      "\n",
      "                         tc_06                    tc_07  \\\n",
      "0      Permanent tooth present  Permanent tooth present   \n",
      "1        Primary tooth present    Primary tooth present   \n",
      "2      Permanent tooth present  Permanent tooth present   \n",
      "3      Permanent tooth present  Permanent tooth present   \n",
      "4      Permanent tooth present  Permanent tooth present   \n",
      "...                        ...                      ...   \n",
      "35904  Permanent tooth present  Permanent tooth present   \n",
      "35905  Permanent tooth present  Permanent tooth present   \n",
      "35906  Permanent tooth present  Permanent tooth present   \n",
      "35907  Permanent tooth present  Permanent tooth present   \n",
      "35908  Permanent tooth present  Permanent tooth present   \n",
      "\n",
      "                         tc_08  ...                 ctc_23  \\\n",
      "0      Permanent tooth present  ...  Sound permanent tooth   \n",
      "1        Primary tooth present  ...    Sound primary tooth   \n",
      "2      Permanent tooth present  ...  Sound permanent tooth   \n",
      "3      Permanent tooth present  ...  Sound permanent tooth   \n",
      "4      Permanent tooth present  ...  Sound permanent tooth   \n",
      "...                        ...  ...                    ...   \n",
      "35904  Permanent tooth present  ...  Sound permanent tooth   \n",
      "35905  Permanent tooth present  ...  Sound permanent tooth   \n",
      "35906  Permanent tooth present  ...  Sound permanent tooth   \n",
      "35907  Permanent tooth present  ...  Sound permanent tooth   \n",
      "35908  Permanent tooth present  ...  Sound permanent tooth   \n",
      "\n",
      "                      ctc_24                 ctc_25                 ctc_26  \\\n",
      "0      Sound permanent tooth  Sound permanent tooth  Sound permanent tooth   \n",
      "1        Sound primary tooth    Sound primary tooth    Sound primary tooth   \n",
      "2      Sound permanent tooth  Sound permanent tooth  Sound permanent tooth   \n",
      "3      Sound permanent tooth  Sound permanent tooth  Sound permanent tooth   \n",
      "4      Sound permanent tooth  Sound permanent tooth  Sound permanent tooth   \n",
      "...                      ...                    ...                    ...   \n",
      "35904  Sound permanent tooth  Sound permanent tooth  Sound permanent tooth   \n",
      "35905  Sound permanent tooth  Sound permanent tooth  Sound permanent tooth   \n",
      "35906  Sound permanent tooth  Sound permanent tooth  Sound permanent tooth   \n",
      "35907  Sound permanent tooth  Sound permanent tooth  Sound permanent tooth   \n",
      "35908  Sound permanent tooth  Sound permanent tooth  Sound permanent tooth   \n",
      "\n",
      "                      ctc_27                 ctc_28  \\\n",
      "0      Sound permanent tooth  Sound permanent tooth   \n",
      "1        Sound primary tooth    Sound primary tooth   \n",
      "2      Sound permanent tooth  Sound permanent tooth   \n",
      "3      Sound permanent tooth  Sound permanent tooth   \n",
      "4      Sound permanent tooth  Sound permanent tooth   \n",
      "...                      ...                    ...   \n",
      "35904  Sound permanent tooth  Sound permanent tooth   \n",
      "35905  Sound permanent tooth  Sound permanent tooth   \n",
      "35906  Sound permanent tooth  Sound permanent tooth   \n",
      "35907  Sound permanent tooth  Sound permanent tooth   \n",
      "35908  Sound permanent tooth  Sound permanent tooth   \n",
      "\n",
      "                                                  ctc_29  \\\n",
      "0                                  Sound permanent tooth   \n",
      "1                                    Sound primary tooth   \n",
      "2                                  Sound permanent tooth   \n",
      "3                                  Sound permanent tooth   \n",
      "4                                  Sound permanent tooth   \n",
      "...                                                  ...   \n",
      "35904                              Sound permanent tooth   \n",
      "35905                              Sound permanent tooth   \n",
      "35906  Permanent tooth with a restored surface condition   \n",
      "35907                              Sound permanent tooth   \n",
      "35908                              Sound permanent tooth   \n",
      "\n",
      "                                                  ctc_30  \\\n",
      "0      Permanent tooth with a dental carious surface ...   \n",
      "1                                              Unerupted   \n",
      "2            Tooth present, condition cannot be assessed   \n",
      "3      Permanent tooth with a dental carious surface ...   \n",
      "4                                  Sound permanent tooth   \n",
      "...                                                  ...   \n",
      "35904                              Sound permanent tooth   \n",
      "35905                              Sound permanent tooth   \n",
      "35906                              Sound permanent tooth   \n",
      "35907                              Sound permanent tooth   \n",
      "35908                              Sound permanent tooth   \n",
      "\n",
      "                                                  ctc_31     cohort  \n",
      "0                                  Sound permanent tooth  2011-2012  \n",
      "1                                              Unerupted  2011-2012  \n",
      "2                                  Sound permanent tooth  2011-2012  \n",
      "3      Permanent tooth with a dental carious surface ...  2011-2012  \n",
      "4                                  Sound permanent tooth  2011-2012  \n",
      "...                                                  ...        ...  \n",
      "35904                              Sound permanent tooth  2017-2018  \n",
      "35905  Permanent tooth with a dental carious surface ...  2017-2018  \n",
      "35906                              Sound permanent tooth  2017-2018  \n",
      "35907  Permanent tooth with a dental carious surface ...  2017-2018  \n",
      "35908                      Missing due to dental disease  2017-2018  \n",
      "\n",
      "[35909 rows x 63 columns]\n",
      "           id  age  gender                race  \\\n",
      "0       62161   22    Male  Non-Hispanic White   \n",
      "1       62162    3  Female    Mexican American   \n",
      "2       62163   14    Male  Non-Hispanic Asian   \n",
      "3       62164   44  Female  Non-Hispanic White   \n",
      "4       62165   14  Female  Non-Hispanic Black   \n",
      "...       ...  ...     ...                 ...   \n",
      "39151  102952   70  Female  Non-Hispanic Asian   \n",
      "39152  102953   42    Male    Mexican American   \n",
      "39153  102954   41  Female  Non-Hispanic Black   \n",
      "39154  102955   14  Female  Non-Hispanic Black   \n",
      "39155  102956   38    Male  Non-Hispanic White   \n",
      "\n",
      "                                    education marital_status  \\\n",
      "0      High school graduate/GED or equivalent  Never married   \n",
      "1                                         NaN            NaN   \n",
      "2                                         NaN            NaN   \n",
      "3                   Some college or AA degree        Married   \n",
      "4                                         NaN            NaN   \n",
      "...                                       ...            ...   \n",
      "39151  High school graduate/GED or equivalent        Married   \n",
      "39152  High school graduate/GED or equivalent      Separated   \n",
      "39153               College graduate or above  Never married   \n",
      "39154                                     NaN            NaN   \n",
      "39155               Some college or AA degree       Divorced   \n",
      "\n",
      "                             exam_status  psu  strata        exam_wt  \\\n",
      "0      Both interviewed and MEC examined    1      91  104236.582554   \n",
      "1      Both interviewed and MEC examined    3      92   16116.354010   \n",
      "2      Both interviewed and MEC examined    3      90    7869.485117   \n",
      "3      Both interviewed and MEC examined    1      94  127965.226204   \n",
      "4      Both interviewed and MEC examined    2      90   13384.042162   \n",
      "...                                  ...  ...     ...            ...   \n",
      "39151  Both interviewed and MEC examined    2     138   18338.711104   \n",
      "39152  Both interviewed and MEC examined    2     137   63661.951573   \n",
      "39153  Both interviewed and MEC examined    1     144   17694.783346   \n",
      "39154  Both interviewed and MEC examined    1     136   14871.839636   \n",
      "39155  Both interviewed and MEC examined    1     142   39426.299948   \n",
      "\n",
      "        interview_wt     cohort  \n",
      "0      102641.406474  2011-2012  \n",
      "1       15457.736897  2011-2012  \n",
      "2        7397.684828  2011-2012  \n",
      "3      127351.373299  2011-2012  \n",
      "4       12209.744980  2011-2012  \n",
      "...              ...        ...  \n",
      "39151   16896.276203  2017-2018  \n",
      "39152   61630.380013  2017-2018  \n",
      "39153   17160.895269  2017-2018  \n",
      "39154   14238.445922  2017-2018  \n",
      "39155   38645.740291  2017-2018  \n",
      "\n",
      "[39156 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ohx)\n",
    "print(demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14c0c3",
   "metadata": {},
   "source": [
    "c)For question a, we have 39156 cases. In b, there are 35909 cases."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
